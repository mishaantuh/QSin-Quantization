{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.function import InplaceFunction, Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model(model, quantize = False, bits = 8, qmode = \"dynamic\"):\n",
    "    if quantize:\n",
    "        print(\"Quantize mode on\")\n",
    "        for layer in model.modules():\n",
    "            try:\n",
    "                mode = layer.mode()\n",
    "                if mode == False:\n",
    "                    layer.change_mod(True, bits, qmode)\n",
    "            except:\n",
    "                continue\n",
    "    else:\n",
    "        print(\"Quantize mode off\")\n",
    "        for layer in model.modules():\n",
    "            try:\n",
    "                mode = layer.mode()\n",
    "                if mode == True:\n",
    "                    layer.change_mod(False, 0)\n",
    "            except:\n",
    "                continue\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qsin_activation_mode(model):\n",
    "    print(\"QSIN activation mode on\")\n",
    "    for layer in model.modules():\n",
    "        try:\n",
    "            mode = layer.mode()\n",
    "            layer.qsinmode()\n",
    "        except:\n",
    "            continue\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRound(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return torch.round(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantize_tensor(input_tensor, max_abs_val = None, num_bits = 8):\n",
    "    my_round = MyRound.apply\n",
    "    qmin = -1.0 * (2**num_bits) / 2\n",
    "    qmax = -qmin - 1\n",
    "    scale = max_abs_val / ((qmax - qmin) / 2)\n",
    "    input_tensor = torch.div(input_tensor, scale)\n",
    "    input_tensor = my_round((input_tensor))\n",
    "    input_tensor = torch.clamp(input_tensor, qmin, qmax)\n",
    "    return torch.mul(input_tensor, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quant(nn.Module):\n",
    "    def __init__(self, num_bits=8, mode = \"dynamic\", static_count = 30):\n",
    "        super(Quant, self).__init__()\n",
    "        self.num_bits = num_bits\n",
    "        self.mode = mode\n",
    "        self.static_count = static_count\n",
    "        self.static_cur = 0\n",
    "        self.stat_values = []\n",
    "        self.max_abs = 0 \n",
    "        if mode != \"dynamic\":\n",
    "            self.max_abs_tr = nn.Parameter(torch.zeros(0), requires_grad=True) # IMPORTANT\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.mode == \"dynamic\":\n",
    "            self.max_abs = torch.max(torch.abs(input.detach()))\n",
    "            return Quantize_tensor(input, self.max_abs, self.num_bits)\n",
    "        \n",
    "        elif self.mode == \"static\":\n",
    "            if self.static_cur > self.static_count:\n",
    "                return Quantize_tensor(input, self.max_abs_tr, self.num_bits)\n",
    "            elif self.static_cur == self.static_count:\n",
    "                self.max_abs = np.mean(self.stat_values)\n",
    "                self.max_abs_tr.data = torch.tensor(self.max_abs, dtype=torch.float).to(self.max_abs_tr.device)\n",
    "                self.static_cur += 1\n",
    "                return Quantize_tensor(input, self.max_abs_tr, self.num_bits)\n",
    "            else:\n",
    "                self.static_cur += 1\n",
    "                self.stat_values.append(np.max(np.absolute(input.cpu().detach().numpy())))\n",
    "                return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QSin(x, num_bits = 8): \n",
    "    pi = torch.tensor(np.pi)\n",
    "    qmin = -1.0 * (2**num_bits) / 2\n",
    "    qmax = -qmin - 1\n",
    "    result = torch.sum(torch.square(torch.sin(torch.mul(pi, x[torch.logical_and(x >= qmin, x <= qmax)]))))\n",
    "    result = result + torch.sum(torch.mul(torch.square(pi), torch.square((x[x < qmin] - qmin))))\n",
    "    result = result + torch.sum(torch.mul(torch.square(pi), torch.square((x[x > qmax] - qmax))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Linear):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, quantization: bool = False, q_bits: int = 8, qsin_activation = False):\n",
    "        super(Linear, self).__init__(in_features, out_features, bias)\n",
    "\n",
    "        self.quantize = True if quantization else False\n",
    "        self.QsinA = True if qsin_activation else False\n",
    "\n",
    "        if self.quantize:\n",
    "            self.bits = q_bits\n",
    "            self.Quantize_weights = Quant(self.bits)\n",
    "            self.Quantize_input = Quant(8) \n",
    "        else:\n",
    "            self.bits = 'FP'\n",
    "            \n",
    "        if self.QsinA:\n",
    "            self.qsin_loss_A = 0\n",
    "\n",
    "    def init(self, input):\n",
    "        self.inputW = input.shape\n",
    "        \n",
    "    def change_mod(self, value, bits = 8, mode = \"dynamic\"):\n",
    "        self.quantize = value\n",
    "        self.bits = bits\n",
    "        self.Quantize_weights = Quant(bits, mode)\n",
    "        self.Quantize_input = Quant(8, mode)\n",
    "        \n",
    "    def qsinmode(self):\n",
    "        self.QsinA = True\n",
    "        self.qsin_loss_A = 0\n",
    "        \n",
    "    def mode(self):\n",
    "        return self.quantize  \n",
    "\n",
    "    def forward(self, input):\n",
    "            \n",
    "        if self.quantize:\n",
    "            qinput = self.Quantize_input(input)\n",
    "            qweight = self.Quantize_weights(self.weight)\n",
    "            \n",
    "            #count qsin loss on activation\n",
    "            if self.QsinA:\n",
    "                self.qsin_loss_A = 0\n",
    "                qmin = -1.0 * (2**8) / 2\n",
    "                qmax = -qmin - 1\n",
    "                scale = self.Quantize_input.max_abs_tr / ((qmax - qmin) / 2)\n",
    "                sq_scale = torch.square(scale)\n",
    "                self.qsin_loss_A = torch.mul(sq_scale, QSin(torch.div(input, scale), 8))\n",
    "            \n",
    "            return nn.functional.linear(qinput, qweight, self.bias)\n",
    "        else:\n",
    "            return nn.functional.linear(input, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Embedding):\n",
    "    def __init__(self, num_embeddings, embedding_dim, padding_idx=None, max_norm=None,\n",
    "                 norm_type=2.0, scale_grad_by_freq=False, sparse=False,\n",
    "                 quantization: bool = False, q_bits: int = 8):\n",
    "        super(Embedding, self).__init__(num_embeddings, embedding_dim, padding_idx)\n",
    "\n",
    "        self.quantize = True if quantization else False\n",
    "\n",
    "        if self.quantize:\n",
    "            self.bits = q_bits\n",
    "            self.Quantize_weights = Quant(self.bits)\n",
    "        else:\n",
    "            self.bits = 'FP'\n",
    "\n",
    "    def init(self, input):\n",
    "        self.inputW = input.shape\n",
    "        \n",
    "    def change_mod(self, value, bits = 8, mode = \"dynamic\"):\n",
    "        self.quantize = value\n",
    "        self.bits = bits\n",
    "        self.Quantize_weights = Quant(bits, mode)\n",
    "        \n",
    "    def mode(self):\n",
    "        return self.quantize  \n",
    "\n",
    "    def forward(self, input):\n",
    "            \n",
    "        if self.quantize:\n",
    "            qweight = self.Quantize_weights(self.weight)\n",
    "        \n",
    "            return nn.functional.embedding(input, qweight, self.padding_idx, self.max_norm,\n",
    "                 self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
    "        else:\n",
    "            return nn.functional.embedding(input, self.weight, self.padding_idx, self.max_norm,\n",
    "                 self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qsin_W(model, bits = 8):\n",
    "    qmin = -1.0 * (2**bits) / 2\n",
    "    qmax = -qmin - 1\n",
    "    loss = 0\n",
    "    for layer in model.modules():\n",
    "        try:\n",
    "            scale = layer.Quantize_weights.max_abs_tr / ((qmax - qmin) / 2)\n",
    "            sq_scale = torch.square(scale)\n",
    "            QSin_w = QSin(torch.div(layer.weight, scale), bits)\n",
    "            loss = loss + torch.mul(sq_scale, QSin_w)\n",
    "        except:\n",
    "            continue\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qsin_A(model):\n",
    "    loss = 0\n",
    "    for layer in model.modules():\n",
    "        try:\n",
    "            loss = loss + layer.qsin_loss_A\n",
    "        except:\n",
    "            continue\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_Linear(in_features, out_features, bias, weight):\n",
    "    linear = Linear(in_features, out_features)\n",
    "    linear.bias = bias\n",
    "    linear.weight = weight\n",
    "    return linear\n",
    "\n",
    "def get_custom_Embeding(num_embeddings, embedding_dim, padding_idx, weight):\n",
    "    embedding = Embedding(num_embeddings, embedding_dim, padding_idx)\n",
    "    embedding.weight = weight\n",
    "    return embedding\n",
    "\n",
    "def change_layers(model):\n",
    "    for name, layer in model.named_children():\n",
    "        #if name == 'intermediate' or \\\n",
    "        #name == 'output'or name == 'embeddings':\n",
    "        #   continue\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            setattr(model, name, get_custom_Linear(\n",
    "                                                layer.in_features,\n",
    "                                                layer.out_features,\n",
    "                                                layer.bias,\n",
    "                                                layer.weight\n",
    "            ))\n",
    "            \n",
    "        if isinstance(layer, nn.Embedding):\n",
    "            setattr(model, name, get_custom_Embeding(\n",
    "                                                layer.num_embeddings,\n",
    "                                                layer.embedding_dim,\n",
    "                                                layer.padding_idx,\n",
    "                                                layer.weight\n",
    "            ))\n",
    "        change_layers(getattr(model, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooler\n",
    "#classifier\n",
    "#attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model(model, quantize = False, bits = 8, qmode = \"dynamic\"):\n",
    "    if quantize:\n",
    "        print(\"Quantize mode on\")\n",
    "        for name, layer in model.named_modules():\n",
    "            try:\n",
    "                mode = layer.mode()\n",
    "                if mode == False:\n",
    "                    if 'classifier' in name: continue \n",
    "                    else: layer.change_mod(True, 8, qmode)\n",
    "            except:\n",
    "                continue\n",
    "    else:\n",
    "        print(\"Quantize mode off\")\n",
    "        for layer in model.modules():\n",
    "            try:\n",
    "                mode = layer.mode()\n",
    "                if mode == True:\n",
    "                    layer.change_mod(False, 0)\n",
    "            except:\n",
    "                continue\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooler\n",
    "#classifier\n",
    "#attention\n",
    "\n",
    "        #if name == 'intermediate' or \\\n",
    "        #name == 'output'or name == 'embeddings':\n",
    "        #    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glue metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "import datasets\n",
    "\n",
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@inproceedings{wang2019glue,\n",
    "  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
    "  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
    "  note={In the Proceedings of ICLR.},\n",
    "  year={2019}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "GLUE, the General Language Understanding Evaluation benchmark\n",
    "(https://gluebenchmark.com/) is a collection of resources for training,\n",
    "evaluating, and analyzing natural language understanding systems.\n",
    "\"\"\"\n",
    "\n",
    "_KWARGS_DESCRIPTION = \"\"\"\n",
    "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
    "Args:\n",
    "    predictions: list of predictions to score.\n",
    "        Each translation should be tokenized into a list of tokens.\n",
    "    references: list of lists of references for each translation.\n",
    "        Each reference should be tokenized into a list of tokens.\n",
    "Returns: depending on the GLUE subset, one or several of:\n",
    "    \"accuracy\": Accuracy\n",
    "    \"f1\": F1 score\n",
    "    \"pearson\": Pearson Correlation\n",
    "    \"spearmanr\": Spearman Correlation\n",
    "    \"matthews_correlation\": Matthew Correlation\n",
    "Examples:\n",
    "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
    "    >>> references = [0, 1]\n",
    "    >>> predictions = [0, 1]\n",
    "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
    "    >>> print(results)\n",
    "    {'accuracy': 1.0}\n",
    "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
    "    >>> references = [0, 1]\n",
    "    >>> predictions = [0, 1]\n",
    "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
    "    >>> print(results)\n",
    "    {'accuracy': 1.0, 'f1': 1.0}\n",
    "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
    "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
    "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
    "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
    "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
    "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
    "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
    "    >>> references = [0, 1]\n",
    "    >>> predictions = [0, 1]\n",
    "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
    "    >>> print(results)\n",
    "    {'matthews_correlation': 1.0}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def acc_and_f1(preds, labels):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "\n",
    "def pearson_and_spearman(preds, labels):\n",
    "    pearson_corr = pearsonr(preds, labels)[0]\n",
    "    spearman_corr = spearmanr(preds, labels)[0]\n",
    "    return {\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"spearmanr\": spearman_corr,\n",
    "    }\n",
    "\n",
    "\n",
    "@datasets.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n",
    "class Glue(datasets.Metric):\n",
    "    def _info(self):\n",
    "        if self.config_name not in [\n",
    "            \"sst2\",\n",
    "            \"mnli\",\n",
    "            \"mnli_mismatched\",\n",
    "            \"mnli_matched\",\n",
    "            \"cola\",\n",
    "            \"stsb\",\n",
    "            \"mrpc\",\n",
    "            \"qqp\",\n",
    "            \"qnli\",\n",
    "            \"rte\",\n",
    "            \"wnli\",\n",
    "            \"hans\",\n",
    "        ]:\n",
    "            raise KeyError(\n",
    "                \"You should supply a configuration name selected in \"\n",
    "                '[\"sst2\", \"mnli\", \"mnli_mismatched\", \"mnli_matched\", '\n",
    "                '\"cola\", \"stsb\", \"mrpc\", \"qqp\", \"qnli\", \"rte\", \"wnli\", \"hans\"]'\n",
    "            )\n",
    "        return datasets.MetricInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            citation=_CITATION,\n",
    "            inputs_description=_KWARGS_DESCRIPTION,\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Value(\"int64\" if self.config_name != \"stsb\" else \"float32\"),\n",
    "                    \"references\": datasets.Value(\"int64\" if self.config_name != \"stsb\" else \"float32\"),\n",
    "                }\n",
    "            ),\n",
    "            codebase_urls=[],\n",
    "            reference_urls=[],\n",
    "            format=\"numpy\",\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references):\n",
    "        if self.config_name == \"cola\":\n",
    "            return {\"matthews_correlation\": matthews_corrcoef(references, predictions)}\n",
    "        elif self.config_name == \"stsb\":\n",
    "            return pearson_and_spearman(predictions, references)\n",
    "        elif self.config_name in [\"mrpc\", \"qqp\"]:\n",
    "            return acc_and_f1(predictions, references)\n",
    "        elif self.config_name in [\"sst2\", \"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]:\n",
    "            return {\"accuracy\": simple_accuracy(predictions, references)}\n",
    "        else:\n",
    "            raise KeyError(\n",
    "                \"You should supply a configuration name selected in \"\n",
    "                '[\"sst2\", \"mnli\", \"mnli_mismatched\", \"mnli_matched\", '\n",
    "                '\"cola\", \"stsb\", \"mrpc\", \"qqp\", \"qnli\", \"rte\", \"wnli\", \"hans\"]'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./models/model-bert-base/', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import DistilBertTokenizer\n",
    "    \n",
    "batch_size = 32\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('./models/tokenizer-bert-base/', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "encoded_dataset = load_from_disk('cur_glue_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "task = 'cola'\n",
    "metric_name = \"pearson\" if task == \"stsb\" else \"matthews_correlation\" if task == \"cola\" else \"accuracy\"\n",
    "metric = metric = Glue(task)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if task != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"test-glue\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./test-glue/checkpoint-1070/',\n",
    "                                                           local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = quantize_model(model, quantize=False, bits = 8)\n",
    "model = quantize_model(model, quantize=True, bits = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval_DQ = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval_DQ.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"test-glue\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    metric_for_best_model=metric_name,\n",
    "    disable_tqdm = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def low_bit_search(model, trainer_args, metric_name, max_drop_level = 40, min_bits = 2):\n",
    "    trainer = Trainer(model, \n",
    "                      trainer_args,  \n",
    "                      eval_dataset=encoded_dataset[validation_key],\n",
    "                      tokenizer=tokenizer, compute_metrics=compute_metrics\n",
    "                    )\n",
    "    best_quality = trainer.evaluate()['eval_'+metric_name]\n",
    "    cur_quality = best_quality\n",
    "    target_quality = best_quality - best_quality * max_drop_level / 100\n",
    "    for name, layer in tqdm(model.named_modules()):\n",
    "        try:\n",
    "            mode = layer.mode()\n",
    "            if mode == True:\n",
    "                while cur_quality >= target_quality:\n",
    "                    num_bits = layer.Quantize_weights.num_bits\n",
    "                    if num_bits == min_bits:\n",
    "                        break\n",
    "                    num_bits -= 1\n",
    "                    layer.change_mod(True, num_bits, \"dynamic\")\n",
    "                    trainer = Trainer(model, args, \n",
    "                                      eval_dataset=encoded_dataset[validation_key],\n",
    "                                      tokenizer=tokenizer, compute_metrics=compute_metrics\n",
    "                                     )\n",
    "                    tmp_quality = trainer.evaluate()['eval_'+metric_name]\n",
    "                    if tmp_quality < target_quality:\n",
    "                        num_bits += 1\n",
    "                        layer.change_mod(True, num_bits, \"dynamic\")\n",
    "                        break\n",
    "                    cur_quality = tmp_quality\n",
    "                        \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return cur_quality\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bit_search(model, args, metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_num_bits = []\n",
    "\n",
    "word_embeddings = 23440896\n",
    "position_embeddings = 393216\n",
    "token_type_embeddings = 1536\n",
    "\n",
    "attention_self_query_weight = 589824\n",
    "intermediate_dense_weight = 2359296\n",
    "output_dense_weight = 2359296\n",
    "\n",
    "p_dense_weight = 589824\n",
    "\n",
    "sz = 0\n",
    "\n",
    "for name, layer in tqdm(model.named_modules()):\n",
    "    try:\n",
    "        mode = layer.mode()\n",
    "        if mode == True:\n",
    "            num_bits = layer.Quantize_weights.num_bits\n",
    "            all_num_bits.append(num_bits)\n",
    "            #print(\"Layer:\",name, \"| bit:\",num_bits)\n",
    "            \n",
    "            if 'word_embeddings' in name:\n",
    "                sz += word_embeddings * num_bits\n",
    "            elif 'position_embeddings' in name:\n",
    "                sz += position_embeddings * num_bits\n",
    "            elif 'token_type_embeddings' in name:\n",
    "                sz += token_type_embeddings * num_bits\n",
    "            elif 'attention' in name:\n",
    "                sz += attention_self_query_weight * num_bits\n",
    "            elif 'intermediate' in name:\n",
    "                sz += intermediate_dense_weight * num_bits\n",
    "            elif 'output.dense' in name:\n",
    "                sz += output_dense_weight * num_bits\n",
    "            elif 'bert.pooler.dense' in name:\n",
    "                sz += p_dense_weight * num_bits\n",
    "                \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz += 768 * 32 * 9 + 3072 * 32\n",
    "437.82041599999997 / (sz / 8 * 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_num_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_static_quantize(model, all_num_bits):\n",
    "    i = 0\n",
    "    for name, layer in tqdm(model.named_modules()):\n",
    "        try:\n",
    "            mode = layer.mode()\n",
    "            if mode == True:\n",
    "                num_bits = all_num_bits[i]\n",
    "                i += 1\n",
    "                layer.change_mod(True, num_bits, \"dynamic\")\n",
    "                        \n",
    "        except:\n",
    "            continue\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    model = new_static_quantize(model, all_num_bits)\n",
    "\n",
    "    trainer = Trainer(model, \n",
    "                      args,  \n",
    "                      eval_dataset=encoded_dataset[validation_key],\n",
    "                      tokenizer=tokenizer, compute_metrics=compute_metrics\n",
    "                    )\n",
    "\n",
    "    trainer.evaluate()\n",
    "    np.random.shuffle(all_num_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_static_quantize(model, all_num_bits):\n",
    "    i = 0\n",
    "    for name, layer in tqdm(model.named_modules()):\n",
    "        try:\n",
    "            mode = layer.mode()\n",
    "            if mode == True:\n",
    "                num_bits = all_num_bits[i]\n",
    "                i += 1\n",
    "                layer.change_mod(True, num_bits, \"static\")\n",
    "                        \n",
    "        except:\n",
    "            continue\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = new_static_quantize(model, all_num_bits)\n",
    "encoded_dataset_static = load_from_disk('cur_glue_data_st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc = encoded_dataset_static['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_enc.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "train_loader = torch.utils.data.DataLoader(train_enc, batch_size=8, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "i = 0\n",
    "for batch in tqdm(train_loader):\n",
    "    i += 1\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['label'].to(device)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    if i == 32:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"test-glue\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    metric_for_best_model=metric_name,\n",
    ")\n",
    "\n",
    "Eval_SQ = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "Eval_SQ.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qsin_W(model):\n",
    "    loss = 0\n",
    "    for layer in model.modules():\n",
    "        try:\n",
    "            bits = layer.Quantize_weights.num_bits\n",
    "            qmin = -1.0 * (2**bits) / 2\n",
    "            qmax = -qmin - 1\n",
    "            scale = layer.Quantize_weights.max_abs_tr / ((qmax - qmin) / 2)\n",
    "            sq_scale = torch.square(scale)\n",
    "            QSin_w = QSin(torch.div(layer.weight, scale), bits)\n",
    "            loss = loss + torch.mul(sq_scale, QSin_w)\n",
    "        except:\n",
    "            continue\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsin_activation_mode(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "class QSinTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        Qsin_W_loss = Qsin_W(model)\n",
    "        Qsin_A_loss = Qsin_A(model)\n",
    "        L = outputs[0]\n",
    "        lambda_w = 10 ** (np.round(np.log10(Qsin_W_loss.cuda().tolist()) - np.log10(L.cuda().tolist())))\n",
    "        lambda_a = 10 ** (np.round(np.log10(Qsin_A_loss.cuda().tolist()) - np.log10(L.cuda().tolist()))+1)\n",
    "        loss = L + Qsin_W_loss / lambda_w + Qsin_A_loss / lambda_a\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"qsin_train_tmp\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    #eval_steps=10, \n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")\n",
    "\n",
    "trainer_QSin = QSinTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_QSin.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"qat_train_tmp\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    #eval_steps=10,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")\n",
    "\n",
    "\n",
    "trainer_QAT = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_QAT.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
