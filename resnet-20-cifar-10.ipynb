{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.autograd.function import InplaceFunction, Function\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.autograd import Variable\nimport math\nimport numpy as np\nimport torchvision.transforms as transforms\nimport torch.nn.init as init\nimport torchvision\nfrom tqdm import tqdm\nimport torch.optim as optim","metadata":{"_uuid":"29ac1ae7-9f69-4de3-a667-94c0f4675ac8","_cell_guid":"df437611-b74f-4d4f-94ff-362c97deddea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def quantize_model(model, quantize = False, bits = 8, qmode = \"dynamic\"):\n    if quantize:\n        print(\"Quantize mode on\")\n        for layer in model.modules():\n            try:\n                mode = layer.mode()\n                if mode == False:\n                    layer.change_mod(True, bits, qmode)\n            except:\n                continue\n    else:\n        print(\"Quantize mode off\")\n        for layer in model.modules():\n            try:\n                mode = layer.mode()\n                if mode == True:\n                    layer.change_mod(False, 0)\n            except:\n                continue\n    return model","metadata":{"_uuid":"ccf7f8f1-03fb-403c-8728-d15bb0a7c74b","_cell_guid":"45527197-0f02-447c-87dc-e25eb6908e83","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def qsin_activation_mode(model):\n    print(\"QSIN activation mode on\")\n    for layer in model.modules():\n        try:\n            mode = layer.mode()\n            layer.qsinmode()\n        except:\n            continue\n    return model","metadata":{"_uuid":"3d198d86-99c1-4a41-9ca5-d42e63ca0025","_cell_guid":"28b5dbc3-7f16-4c4b-9e0d-fbdd593b701a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyRound(torch.autograd.Function):\n    \n    @staticmethod\n    def forward(ctx, input):\n        return torch.round(input)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        return grad_output","metadata":{"_uuid":"5fbd7258-c143-4a2d-b1c6-6f45c01618b6","_cell_guid":"9b33cb38-a57e-47cc-8cbc-07ed40184213","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Quantize_tensor(input_tensor, max_abs_val = None, num_bits = 8):\n    my_round = MyRound.apply\n    qmin = -1.0 * (2**num_bits) / 2\n    qmax = -qmin - 1\n    scale = max_abs_val / ((qmax - qmin) / 2)\n    input_tensor = torch.div(input_tensor, scale)\n    input_tensor = my_round((input_tensor))\n    input_tensor = torch.clamp(input_tensor, qmin, qmax)\n    return torch.mul(input_tensor, scale)","metadata":{"_uuid":"1bb041ee-8c9b-4589-b649-3e02a8344838","_cell_guid":"14283711-453f-4d52-bc95-e6b5656f665f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Quant(nn.Module):\n    def __init__(self, num_bits=8, mode = \"dynamic\", static_count = 30):\n        super(Quant, self).__init__()\n        self.num_bits = num_bits\n        self.mode = mode\n        self.static_count = static_count\n        self.static_cur = 0\n        self.stat_values = []\n        self.max_abs = 0 \n        self.max_abs_tr = nn.Parameter(torch.zeros(0), requires_grad=True) # IMPORTANT\n        \n    def forward(self, input):\n        if self.mode == \"dynamic\":\n            self.max_abs = torch.max(torch.abs(input))\n            return Quantize_tensor(input, self.max_abs, self.num_bits)\n        \n        elif self.mode == \"static\":\n            if self.static_cur > self.static_count:\n                return Quantize_tensor(input, self.max_abs_tr, self.num_bits)\n            elif self.static_cur == self.static_count:\n                self.max_abs = np.mean(self.stat_values)\n                self.max_abs_tr.data = torch.tensor(self.max_abs, dtype=torch.float).to(self.max_abs_tr.device)\n                self.static_cur += 1\n                return Quantize_tensor(input, self.max_abs_tr, self.num_bits)\n            else:\n                self.static_cur += 1\n                self.stat_values.append(np.max(np.absolute(input.cpu().detach().numpy())))\n                return input","metadata":{"_uuid":"22a3ee00-ce3a-450e-b1f1-1f5d88dcb469","_cell_guid":"5e021804-11c0-4cfc-b023-554764f0abd6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def QSin(x, num_bits = 8): \n    pi = torch.tensor(np.pi)\n    qmin = -1.0 * (2**num_bits) / 2\n    qmax = -qmin - 1\n    result = torch.sum(torch.square(torch.sin(torch.mul(pi, x[torch.logical_and(x >= qmin, x <= qmax)]))))\n    result = result + torch.sum(torch.mul(torch.square(pi), torch.square((x[x < qmin] - qmin))))\n    result = result + torch.sum(torch.mul(torch.square(pi), torch.square((x[x > qmax] - qmax))))\n    return result","metadata":{"_uuid":"677a8229-35ae-482f-a0a9-50910c0717a4","_cell_guid":"b9be4b02-3b48-4b9b-a0b7-b82d2fa6622d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Conv2d(nn.Conv2d):\n    def __init__(self, inCh: int, outCh: int, kernel_size: int = 4, stride: int = 1, padding: int = 0,\n                 bias: bool = None, quantization: bool = False, q_bits: int = 8, qsin_activation = False):\n        super(Conv2d,self).__init__(inCh, outCh, kernel_size, stride=stride, padding = padding, bias = bias)\n\n        self.quantize = True if quantization else False\n        self.QsinA = True if qsin_activation else False\n\n        if self.quantize:\n            self.bits = q_bits\n            self.Quantize_weights = Quant(self.bits)\n            self.Quantize_input = Quant(self.bits)\n        else:\n            self.bits = 'FP'\n            \n        if self.QsinA:\n            self.qsin_loss_A = 0\n\n    def init(self, input):\n        self.inputW = input.shape\n\n    def change_mod(self, value, bits = 8, mode = \"dynamic\"):\n        self.quantize = value\n        self.bits = bits\n        self.Quantize_weights = Quant(bits,mode)\n        self.Quantize_input = Quant(bits, mode)\n    \n    def qsinmode(self):\n        self.QsinA = True\n        self.qsin_loss_A = 0\n\n    def mode(self):\n        return self.quantize  \n\n    def forward(self, input):\n        if self.quantize:\n            qinput = self.Quantize_input(input)\n            qweight = self.Quantize_weights(self.weight)\n            \n            \n            #count qsin loss on activation\n            if self.QsinA:\n                self.qsin_loss_A = 0\n                qmin = -1.0 * (2**self.bits) / 2\n                qmax = -qmin - 1\n                scale = self.Quantize_input.max_abs_tr / ((qmax - qmin) / 2)\n                sq_scale = torch.square(scale)\n                self.qsin_loss_A = torch.mul(sq_scale, QSin(torch.div(input, scale), self.bits))\n                \n                \n            return nn.functional.conv2d(qinput, qweight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n\n        else:\n            return nn.functional.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)","metadata":{"_uuid":"1c6d73f6-dbdb-4d98-a7ba-9f2645191c19","_cell_guid":"c234dfd8-9676-42d9-8c71-f8979a6c1760","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Linear(nn.Linear):\n    def __init__(self, inFeatures: int, outFeatures: int, bias: bool = True, quantization: bool = False, q_bits: int = 8, qsin_activation = False):\n        super(Linear, self).__init__(inFeatures, outFeatures, bias)\n\n        self.quantize = True if quantization else False\n        self.QsinA = True if qsin_activation else False\n\n        if self.quantize:\n            self.bits = q_bits\n            self.Quantize_weights = Quant(self.bits)\n            self.Quantize_input = Quant(self.bits)\n        else:\n            self.bits = 'FP'\n            \n        if self.QsinA:\n            self.qsin_loss_A = 0\n\n    def init(self, input):\n        self.inputW = input.shape\n        \n    def change_mod(self, value, bits = 8, mode = \"dynamic\"):\n        self.quantize = value\n        self.bits = bits\n        self.Quantize_weights = Quant(bits, mode)\n        self.Quantize_input = Quant(bits, mode)\n        \n    def qsinmode(self):\n        self.QsinA = True\n        self.qsin_loss_A = 0\n        \n    def mode(self):\n        return self.quantize  \n\n    def forward(self, input):\n            \n        if self.quantize:\n            qinput = self.Quantize_input(input)\n            qweight = self.Quantize_weights(self.weight)\n            \n            #count qsin loss on activation\n            if self.QsinA:\n                self.qsin_loss_A = 0\n                qmin = -1.0 * (2**self.bits) / 2\n                qmax = -qmin - 1\n                scale = self.Quantize_input.max_abs_tr / ((qmax - qmin) / 2)\n                sq_scale = torch.square(scale)\n                self.qsin_loss_A = torch.mul(sq_scale, QSin(torch.div(input, scale), self.bits))\n            \n            return nn.functional.linear(qinput, qweight, self.bias)\n        else:\n            return nn.functional.linear(input, self.weight, self.bias)","metadata":{"_uuid":"304c3753-5d2a-45bc-aeb7-f104b7c9b9cc","_cell_guid":"a4e7d7b5-6e7d-4d1b-9e7e-0b8bed4f935c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Qsin_W(model, bits = 8):\n    qmin = -1.0 * (2**bits) / 2\n    qmax = -qmin - 1\n    loss = 0\n    for layer in model.modules():\n        try:\n            scale = layer.Quantize_weights.max_abs_tr / ((qmax - qmin) / 2)\n            sq_scale = torch.square(scale)\n            QSin_w = QSin(torch.div(layer.weight, scale), bits)\n            loss = loss + torch.mul(sq_scale, QSin_w)\n        except:\n            continue\n    return loss","metadata":{"_uuid":"6f401687-e882-4696-aa95-dd0480fa37f0","_cell_guid":"91a7a5c8-6e2a-4547-8140-7579fc77660a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Qsin_A(model):\n    loss = 0\n    for layer in model.modules():\n        try:\n            loss = loss + layer.qsin_loss_A\n        except:\n            continue\n    return loss","metadata":{"_uuid":"7f991fd3-6016-4298-9d84-9d583550440f","_cell_guid":"a8ef7c01-ee08-4a0f-97a3-286d9daeb16c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model and train","metadata":{"_uuid":"2150d0e2-b7f2-4e0a-b3fa-aef7de039d8f","_cell_guid":"ebf61c09-efb7-49a5-860c-0661316cd215","trusted":true}},{"cell_type":"code","source":"def _weights_init(m):\n    classname = m.__class__.__name__\n    if isinstance(m, Linear) or isinstance(m, Conv2d):\n        init.kaiming_normal(m.weight)\n\n\nclass LambdaLayer(nn.Module):\n    def __init__(self, lambd, planes):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n        self.planes = planes\n\n    def forward(self, x):\n        return self.lambd(x, self.planes)\n\n\ndef pad_func(x, planes):\n    return F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = Conv2d(\n            in_planes, planes, kernel_size=3, \n            stride=stride, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = Conv2d(\n            planes, planes, kernel_size=3, \n            stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = LambdaLayer(pad_func, planes)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = Conv2d(\n            3, 16, kernel_size=3, \n            stride=1, padding=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n        self.linear = Linear(64, num_classes)\n\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        out = torch.flatten(out, 1)\n        out = self.linear(out)\n\n        return out","metadata":{"_uuid":"7bd01a09-e439-4358-95bb-8b968b5c20c6","_cell_guid":"7fdec1e0-3081-415a-aa11-46236fb6875d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet(BasicBlock, [3, 3, 3], 10)","metadata":{"_uuid":"b7defcbe-8677-4d8e-a6d2-02dd2faff69f","_cell_guid":"b590f7ee-55e5-48a0-9dc7-203ad37edb0c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = '../input/resnet20/resnet_20_cifar10_91.73.pth'\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncheckpoint = torch.load(checkpoint_path)\nmodel.load_state_dict(checkpoint['state'])\nmodel.to(device)\nprint('loaded')","metadata":{"_uuid":"dbb25119-c7df-49d5-a693-0c33b94279e2","_cell_guid":"a4d9b7e4-eebb-45cf-9fb7-c7cc8f711ac2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\ntransform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    normalize,\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    normalize,\n])","metadata":{"_uuid":"04b93171-1ffa-4265-9c99-895c19e9be1f","_cell_guid":"52650fe8-b72a-436c-a934-fc3ee5218a31","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=100, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(\n    root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=100, shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"_uuid":"a268738f-4416-4579-b24e-f914c5df1f71","_cell_guid":"06ed9978-7f36-4074-859f-ddf9747e3b80","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(net, epoch = 0):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    for data, target in trainloader:\n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        output = net(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * data.size(0)\n        _, predicted = torch.max(output.data, 1)\n        total_train += target.size(0)\n        correct_train += (predicted == target).float().sum()\n        accuracy_train = correct_train / total_train\n        train_loss = train_loss/len(trainloader.sampler)\n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.6f}'.format(epoch, train_loss, accuracy_train))\n\n\ndef test(net, epoch = 0):\n    valid_loss = 0.0\n    correct_valid = 0\n    total_valid = 0\n    net.eval()\n    for data, target in testloader:\n        data = data.to(device)\n        target = target.to(device)\n        output = net(data)\n        loss = criterion(output, target)\n        \n        valid_loss += loss.item() * data.size(0)\n        \n        _, predicted = torch.max(output.data, 1)\n        total_valid += target.size(0)\n        correct_valid += (predicted == target).float().sum()\n        valid_loss = valid_loss/len(testloader.sampler)\n        accuracy_valid = correct_valid / total_valid\n    print('Epoch: {} \\tTest Loss: {:.6f} \\tTest Accuracy: {:.6f}'.format(epoch, valid_loss, accuracy_valid))\n    return accuracy_valid","metadata":{"_uuid":"2fe633a0-379c-4d46-84a5-c2f06afd6334","_cell_guid":"00f7715e-3e0f-456a-bbb4-c1568eb43549","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n#model = quantize_model(model, quantize=False, bits = 4)\ntest(model)","metadata":{"_uuid":"d8bec1a1-5051-4140-a19c-ab90ff709519","_cell_guid":"70614982-cb90-46e2-a689-13251e9d9125","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = quantize_model(model, quantize=False, bits = 4)\nmodel = quantize_model(model, quantize=True, bits = 4)\nmodel.to(device)\ntest(model)","metadata":{"_uuid":"2b66d502-53e5-4d97-8212-1f793b009fa5","_cell_guid":"b7cdd2ba-4a1f-44e4-95bd-211253299b47","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nmodel = quantize_model(model, quantize=False, bits = 4)\nmodel = quantize_model(model, quantize=True, bits = 4, qmode = \"static\")\nmodel.to(device)\ni = 0\nmodel.eval()\nfor data, target in trainloader:\n    i+=1\n    if i == 35:\n        break\n    data = data.to(device)\n    target = target.to(device)\n    output = model(data)\n\ntest(model)","metadata":{"_uuid":"0641ab24-f84a-44c2-b25d-99d4c91b874f","_cell_guid":"81a24605-6217-44d5-a11d-4dd11c89ec5c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# QSIN","metadata":{"_uuid":"8d4309fa-b4bc-489e-8e63-5ca92247850a","_cell_guid":"147236bb-0c19-4ed8-badc-5696f34cd89a","trusted":true}},{"cell_type":"code","source":"qsin_activation_mode(model)\nprint()","metadata":{"_uuid":"5af31a8f-0f68-4455-96c0-0fc8f0d49ba9","_cell_guid":"b6d84a19-d0e0-4727-a2d2-c2d9578ce63e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Qsin_W(model, 4)","metadata":{"_uuid":"4ed6066f-11fb-4bd3-85e3-902a0ce7148e","_cell_guid":"ba78fbfb-4365-4a6b-8d76-1b0c3a48b3cb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=5e-4)\n\nloss_w = []\nloss_a = []\naccuracy_all = []\n\nj = 0\nfor i in tqdm(range(70)):\n    model.train()\n    for data, target in trainloader:\n        \n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        \n        if j % 50 == 0:\n            lambda_w = 1 / 1000\n            lambda_a = 1 / 10000000\n            loss_w.append(Qsin_W(model, 4).cpu().detach())\n            loss_a.append(Qsin_A(model).cpu().detach())\n            accuracy_valid = test(model)\n            accuracy_all.append(accuracy_valid)\n            \n        j+=1\n        \n        lambda_w = 1 / 1000\n        lambda_a = 1 / 10000000\n        loss = criterion(output, target) + lambda_w * Qsin_W(model, 8) + lambda_a * Qsin_A(model)\n        loss.backward()\n        optimizer.step()","metadata":{"_uuid":"a8921f9f-33f9-47ab-a664-8f5a66ea1f6f","_cell_guid":"6ac5ed0a-81b3-4f8b-af52-f4c8363ea7c3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# QAT","metadata":{"_uuid":"fc1a5409-66f8-47e7-98c2-a80ea106f390","_cell_guid":"6241473a-fe1e-480c-b762-b72404238b6f","trusted":true}},{"cell_type":"code","source":"import torch.optim as optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=5e-4)\n\naccuracy_all = []\n\nj = 0\nfor i in tqdm(range(70)):\n    model.train()\n    for data, target in trainloader:\n        \n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        \n        if j % 50 == 0:\n            accuracy_valid = test(model)\n            accuracy_all.append(accuracy_valid)\n            \n        j+=1\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"42d2320b-ce58-4f54-80b9-6bf0641ba0dd","_cell_guid":"654514a1-e212-46a0-ad81-d68b8a3a0f95","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}